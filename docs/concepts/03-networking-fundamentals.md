# 네트워크 기초

> *"네트워크는 보이지 않을 때 가장 잘 작동하고 있는 것이다. 하지만 문제가 생기면, 그것을 이해하지 못하는 사람에게는 마법처럼 보인다."*
> — Unknown Network Engineer

Kubernetes 클러스터에서 Pod가 다른 Pod와 통신하고, Service가 트래픽을 로드밸런싱하고, 외부 요청이 올바른 애플리케이션에 도달하는 것은 모두 네트워킹 덕분입니다. 이 장에서는 Kubernetes 네트워킹을 이해하기 위한 필수 네트워크 기초 개념을 다룹니다.

네트워크 문제는 종종 "연결이 안 된다"라는 모호한 증상으로 나타납니다. 하지만 OSI 계층 모델을 이해하면, 문제가 L2(MAC 주소)인지, L3(IP 라우팅)인지, L4(포트/방화벽)인지 체계적으로 진단할 수 있습니다.

---

## 이 장에서 다루는 내용

이 장을 읽고 나면 다음을 이해할 수 있습니다:

- **OSI 7계층 모델**: 네트워크 통신의 계층 구조와 각 계층의 역할
- **TCP/IP 스택**: 실제 인터넷에서 사용되는 프로토콜 스택
- **IP 주소와 서브넷**: CIDR 표기법과 서브넷 계산
- **라우팅**: 패킷이 목적지를 찾아가는 방법
- **NAT**: SNAT/DNAT와 Kubernetes Service의 관계
- **Linux 가상 네트워크 장치**: veth, bridge, TUN/TAP
- **오버레이 네트워크**: VXLAN의 동작 원리
- **iptables와 netfilter**: Linux 방화벽과 패킷 처리

> **📘 개념 (Concept)**: 이 장의 모든 개념은 Kubernetes의 Service, Ingress, NetworkPolicy가 내부적으로 사용하는 기술들입니다. 네트워크 기초를 이해하면 "Service가 왜 연결되지 않는가?"를 근본적으로 해결할 수 있습니다.

---

## 1. OSI 7계층 모델

### 1.1. 왜 계층 모델이 필요한가?

네트워크 통신은 매우 복잡합니다. 전기 신호를 비트로 변환하고, 프레임을 구성하고, 패킷을 라우팅하고, 연결을 관리하고, 데이터를 암호화하고... 이 모든 것을 하나의 시스템에서 처리하면 유지보수가 불가능해집니다.

OSI(Open Systems Interconnection) 모델은 이 복잡성을 7개의 계층으로 분리합니다. 각 계층은 특정 역할만 담당하고, 인접 계층과만 통신합니다. 이렇게 하면:

- **모듈화**: 한 계층을 변경해도 다른 계층에 영향 없음
- **표준화**: 각 계층의 프로토콜을 독립적으로 정의
- **문제 해결**: 어느 계층에서 문제가 발생했는지 쉽게 파악

> **💡 팁 (Tip)**: 네트워크 문제 해결 시 "어느 계층의 문제인가?"를 먼저 파악하세요. L1(케이블 연결), L2(MAC/ARP), L3(IP/라우팅), L4(포트/방화벽), L7(애플리케이션) 순으로 점검하면 효율적입니다.

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                          OSI 7계층 모델                                      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   계층                    데이터 단위    프로토콜/장비           역할        │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │  7. Application       │ Data      │ HTTP, DNS, SSH    │ 사용자 인터페이스│
│  │     (응용)            │           │ gRPC, HTTPS       │ 애플리케이션     │
│  ├─────────────────────────────────────────────────────────────────────┤   │
│  │  6. Presentation      │ Data      │ SSL/TLS, JPEG     │ 데이터 형식 변환│
│  │     (표현)            │           │ 압축, 암호화      │ 인코딩/디코딩    │
│  ├─────────────────────────────────────────────────────────────────────┤   │
│  │  5. Session           │ Data      │ NetBIOS, RPC      │ 세션 관리       │
│  │     (세션)            │           │ 연결 설정/해제    │ 동기화          │
│  ├─────────────────────────────────────────────────────────────────────┤   │
│  │  4. Transport         │ Segment   │ TCP, UDP          │ 종단 간 통신    │
│  │     (전송)            │           │ 포트 번호         │ 흐름/오류 제어  │
│  ├─────────────────────────────────────────────────────────────────────┤   │
│  │  3. Network           │ Packet    │ IP, ICMP          │ 라우팅, 주소    │
│  │     (네트워크)         │           │ 라우터            │ 논리적 주소     │
│  ├─────────────────────────────────────────────────────────────────────┤   │
│  │  2. Data Link         │ Frame     │ Ethernet, ARP     │ 물리 주소       │
│  │     (데이터 링크)      │           │ 스위치, 브리지    │ MAC 주소        │
│  ├─────────────────────────────────────────────────────────────────────┤   │
│  │  1. Physical          │ Bit       │ 케이블, 허브      │ 전기/광 신호    │
│  │     (물리)            │           │ NIC               │ 비트 전송       │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
│   Kubernetes/Cilium 관련 계층:                                              │
│   • L7: Ingress, HTTP 라우팅, gRPC 로드밸런싱                               │
│   • L4: Service (ClusterIP, NodePort, LoadBalancer)                        │
│   • L3: Pod IP, CNI 라우팅, Network Policy                                 │
│   • L2: 노드 내 브리지, veth, ARP                                          │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

### 1.2. 데이터 캡슐화

데이터가 네트워크를 통해 전송될 때, 각 계층은 자신의 헤더를 추가합니다. 이것을 **캡슐화(Encapsulation)**라고 합니다.

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                         데이터 캡슐화 과정                                    │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   송신측 (캡슐화)                                                           │
│                                                                             │
│   Application    ┌─────────────────────────────────────┐                   │
│                  │              Data                    │                   │
│                  │         "GET / HTTP/1.1"            │                   │
│                  └─────────────────────────────────────┘                   │
│                                    │                                       │
│                                    ▼                                       │
│   Transport      ┌──────┬─────────────────────────────┐                   │
│                  │TCP   │              Data           │                   │
│                  │Hdr   │  Src Port: 54321            │                   │
│                  │(20B) │  Dst Port: 80               │                   │
│                  └──────┴─────────────────────────────┘                   │
│                         Segment (세그먼트)                                 │
│                                    │                                       │
│                                    ▼                                       │
│   Network        ┌────┬──────┬─────────────────────────┐                   │
│                  │ IP │TCP   │         Data           │                   │
│                  │Hdr │Hdr   │  Src IP: 10.200.0.10   │                   │
│                  │(20B)      │  Dst IP: 10.200.1.20   │                   │
│                  └────┴──────┴─────────────────────────┘                   │
│                              Packet (패킷)                                 │
│                                    │                                       │
│                                    ▼                                       │
│   Data Link      ┌───┬────┬──────┬───────────────────┬───┐                │
│                  │Eth│ IP │TCP   │       Data        │FCS│                │
│                  │Hdr│Hdr │Hdr   │  Src MAC: aa:bb.. │   │                │
│                  │14B│    │      │  Dst MAC: cc:dd.. │4B │                │
│                  └───┴────┴──────┴───────────────────┴───┘                │
│                                   Frame (프레임)                           │
│                                    │                                       │
│                                    ▼                                       │
│   Physical       01101001 10110100 11010010 ... (비트 스트림)               │
│                  전기 신호 또는 광 신호로 변환                               │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

> **📝 예제 (Example)**: Pod A(10.200.0.10)에서 Pod B(10.200.1.20)의 웹 서버(포트 80)에 접속할 때, HTTP 요청 데이터는 TCP 헤더(포트 정보), IP 헤더(IP 주소), 이더넷 헤더(MAC 주소)로 순차적으로 감싸집니다. 수신측에서는 역순으로 헤더를 벗겨내며 처리합니다.

### 1.3. 각 계층의 역할 상세

| 계층 | 역할 | Kubernetes에서 | 문제 해결 포인트 |
|------|------|----------------|-----------------|
| **L7 (Application)** | 애플리케이션 프로토콜 | Ingress, HTTP 라우팅 | 404, 502 에러, TLS 인증서 |
| **L4 (Transport)** | 포트, 연결 관리 | Service, iptables | Connection refused, 타임아웃 |
| **L3 (Network)** | IP 라우팅 | CNI, Pod CIDR | No route to host, 라우팅 테이블 |
| **L2 (Data Link)** | MAC 주소, 스위칭 | Bridge, veth | ARP 캐시, 브리지 설정 |
| **L1 (Physical)** | 물리적 연결 | 케이블, NIC | 링크 상태, 케이블 연결 |

### 섹션 요약

- OSI 모델은 네트워크 통신을 **7개 계층**으로 분리
- 각 계층은 **특정 역할**만 담당하고 인접 계층과만 통신
- 데이터는 송신 시 **캡슐화**, 수신 시 **역캡슐화**
- 문제 해결 시 **계층별로 점검**하면 효율적

---

## 2. TCP/IP 스택

### 2.1. TCP/IP 4계층 모델

실제 인터넷에서 사용되는 프로토콜 스택은 OSI 7계층보다 단순한 TCP/IP 4계층 모델입니다.

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                     TCP/IP 4계층 vs OSI 7계층                                │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   OSI 7계층                          TCP/IP 4계층                           │
│  ┌─────────────────┐                ┌─────────────────┐                    │
│  │  7. Application │                │                 │                    │
│  ├─────────────────┤                │  4. Application │   HTTP, DNS,      │
│  │  6. Presentation│  ──────────►   │                 │   SSH, FTP,       │
│  ├─────────────────┤                │                 │   gRPC            │
│  │  5. Session     │                └─────────────────┘                    │
│  ├─────────────────┤                ┌─────────────────┐                    │
│  │  4. Transport   │  ──────────►   │  3. Transport   │   TCP, UDP        │
│  ├─────────────────┤                └─────────────────┘                    │
│  │  3. Network     │  ──────────►   ┌─────────────────┐                    │
│  │                 │                │  2. Internet    │   IP, ICMP, ARP   │
│  ├─────────────────┤                └─────────────────┘                    │
│  │  2. Data Link   │                ┌─────────────────┐                    │
│  ├─────────────────┤  ──────────►   │  1. Network     │   Ethernet,       │
│  │  1. Physical    │                │     Access      │   Wi-Fi, PPP      │
│  └─────────────────┘                └─────────────────┘                    │
│                                                                             │
│   실무에서는 TCP/IP 모델을 더 많이 사용합니다.                               │
│   OSI는 개념적 참조 모델로 활용합니다.                                       │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

### 2.2. TCP vs UDP

| 항목 | TCP | UDP |
|------|-----|-----|
| **연결 방식** | 연결 지향 (3-way handshake) | 비연결 |
| **신뢰성** | 보장 (재전송, 순서 보장) | 미보장 |
| **흐름 제어** | 있음 (윈도우 기반) | 없음 |
| **혼잡 제어** | 있음 | 없음 |
| **속도** | 상대적으로 느림 | 빠름 |
| **헤더 크기** | 20+ 바이트 | 8 바이트 |
| **사용 예** | HTTP, SSH, 데이터베이스, API | DNS, 스트리밍, VXLAN, 게임 |
| **Kubernetes** | 대부분의 Service | DNS (kube-dns), VXLAN 터널 |

> **🔍 심화 학습 (Deep Dive)**: Cilium은 UDP 기반의 VXLAN 터널링을 사용할 수 있습니다. VXLAN은 L2 프레임을 L3 패킷으로 캡슐화하여, 다른 네트워크 세그먼트에 있는 노드 간에도 L2 통신이 가능하게 합니다.

### 2.3. TCP 3-Way Handshake 상세

TCP 연결은 3단계 핸드셰이크로 시작됩니다. 이 과정이 실패하면 "Connection refused" 또는 "Connection timed out" 에러가 발생합니다.

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                      TCP 3-Way Handshake                                    │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   Client (Pod A)                                      Server (Pod B)        │
│   10.200.0.10:54321                                  10.200.1.20:80         │
│     │                                                    │                  │
│     │  1. SYN (seq=1000)                                │                  │
│     │ ─────────────────────────────────────────────────►│                  │
│     │    "연결하고 싶어요, 내 초기 시퀀스 번호는 1000"     │                  │
│     │                                                    │ SYN_RECEIVED     │
│     │                                                    │                  │
│     │  2. SYN-ACK (seq=2000, ack=1001)                  │                  │
│     │◄───────────────────────────────────────────────── │                  │
│     │    "알겠어요, 내 시퀀스 번호는 2000, 1001 기다려요" │                  │
│     │                                                    │                  │
│     │  3. ACK (seq=1001, ack=2001)                      │                  │
│     │ ─────────────────────────────────────────────────►│                  │
│     │    "2001 기다려요, 연결 완료!"                      │ ESTABLISHED      │
│     │                                                    │                  │
│     │  ═══════════ Connection Established ══════════    │                  │
│     │                                                    │                  │
│     │  4. Data Transfer (HTTP Request)                  │                  │
│     │ ─────────────────────────────────────────────────►│                  │
│     │                                                    │                  │
│     │  5. ACK + Data (HTTP Response)                    │                  │
│     │◄───────────────────────────────────────────────── │                  │
│     │                                                    │                  │
│                                                                             │
│   연결 종료: 4-Way Handshake (FIN → ACK → FIN → ACK)                        │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

> **⚠️ 주의 (Warning)**: 3-way handshake 중 SYN 패킷에 응답이 없으면 "Connection timed out"이 발생합니다. 이는 보통 방화벽(iptables, NetworkPolicy)이 패킷을 차단하거나, 목적지 서버가 해당 포트에서 리스닝하지 않기 때문입니다.

**연결 문제 진단:**

\`\`\`bash
# TCP 연결 테스트
nc -zv 10.200.1.20 80
# Connection to 10.200.1.20 80 port [tcp/http] succeeded!

# 연결 실패 시 원인 분석
# 1. "Connection refused" → 포트가 열려있지 않음
# 2. "Connection timed out" → 방화벽 또는 라우팅 문제
# 3. "No route to host" → 라우팅 테이블 문제

# 현재 TCP 연결 상태 확인
ss -tn state established
# 또는
netstat -tn | grep ESTABLISHED
\`\`\`

### 섹션 요약

- TCP/IP는 **4계층** 모델로 실제 인터넷에서 사용
- **TCP**는 신뢰성 있는 연결, **UDP**는 빠른 비연결 통신
- TCP 연결은 **3-way handshake**로 시작
- 연결 실패 시 **"refused"**(포트 닫힘)와 **"timed out"**(방화벽/라우팅) 구분

---

## 3. IP 주소와 서브넷

### 3.1. IPv4 주소 구조

IPv4 주소는 32비트 숫자로, 네트워크 부분과 호스트 부분으로 나뉩니다.

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                         IPv4 주소 구조                                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   IP 주소: 192.168.1.100                                                    │
│                                                                             │
│   십진수:     192    .    168    .     1     .    100                       │
│             ──────      ──────       ─────       ─────                      │
│   이진수:   11000000   10101000    00000001    01100100                     │
│                                                                             │
│   32비트 = 4 옥텟 (각 8비트, 0-255 범위)                                    │
│                                                                             │
│   ┌────────────────────────────────────────────────────────────────────┐   │
│   │  Network Part (네트워크 부분)  │  Host Part (호스트 부분)           │   │
│   │  192.168.1                    │  .100                              │   │
│   │  (동일 네트워크 식별)          │  (네트워크 내 개별 호스트 식별)      │   │
│   └────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
│   서브넷 마스크: 255.255.255.0 (/24)                                        │
│   이진수:       11111111.11111111.11111111.00000000                         │
│                 ────────────────────────── ────────                         │
│                 네트워크 비트 (24개)        호스트 비트 (8개)                 │
│                                                                             │
│   네트워크 주소 계산 (AND 연산):                                             │
│   IP 주소:      192.168.1.100   (11000000.10101000.00000001.01100100)      │
│   서브넷 마스크: 255.255.255.0   (11111111.11111111.11111111.00000000)      │
│   ─────────────────────────────────────────────────────────────────────    │
│   네트워크 주소: 192.168.1.0     (11000000.10101000.00000001.00000000)      │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

> **📘 개념 (Concept)**: 같은 네트워크에 있는 호스트끼리는 라우터 없이 직접 통신할 수 있습니다. 다른 네트워크로 가려면 반드시 게이트웨이(라우터)를 거쳐야 합니다.

### 3.2. CIDR 표기법

CIDR(Classless Inter-Domain Routing)은 IP 주소와 서브넷 마스크를 간결하게 표기하는 방법입니다.

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                           CIDR 표기법                                        │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   표기: IP주소/프리픽스 길이                                                 │
│   예: 192.168.1.0/24 = 192.168.1.0 ~ 192.168.1.255                         │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  CIDR       │ 서브넷 마스크     │ 호스트 수  │ 사용 예              │  │
│   ├─────────────┼─────────────────┼───────────┼─────────────────────┤  │
│   │  /8         │ 255.0.0.0       │ 16,777,214│ 대규모 사설망 (10.x) │  │
│   │  /12        │ 255.240.0.0     │ 1,048,574 │ 172.16.0.0/12       │  │
│   │  /16        │ 255.255.0.0     │ 65,534    │ Pod CIDR            │  │
│   │  /18        │ 255.255.192.0   │ 16,382    │ Service CIDR        │  │
│   │  /24        │ 255.255.255.0   │ 254       │ 노드당 Pod CIDR     │  │
│   │  /25        │ 255.255.255.128 │ 126       │ 작은 서브넷          │  │
│   │  /26        │ 255.255.255.192 │ 62        │                     │  │
│   │  /27        │ 255.255.255.224 │ 30        │                     │  │
│   │  /28        │ 255.255.255.240 │ 14        │                     │  │
│   │  /30        │ 255.255.255.252 │ 2         │ Point-to-Point      │  │
│   │  /32        │ 255.255.255.255 │ 1         │ 단일 호스트 (Pod IP) │  │
│   └─────────────┴─────────────────┴───────────┴─────────────────────┘  │
│                                                                             │
│   호스트 수 계산: 2^(32-프리픽스) - 2                                        │
│   (-2는 네트워크 주소와 브로드캐스트 주소 제외)                               │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

### 3.3. Kubernetes 네트워크 CIDR 설계

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                    Kubernetes CIDR 설계 예시                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   물리 네트워크: 192.168.108.0/24 (노드 IP)                                 │
│   ├── Control Plane: 192.168.108.11-13                                     │
│   ├── Workers: 192.168.108.21-40                                           │
│   └── Repo Server: 192.168.108.201                                         │
│                                                                             │
│   Pod CIDR: 10.200.0.0/16 (Cilium IPAM)                                    │
│   ├── Node 1: 10.200.0.0/24 (254 Pods)                                     │
│   ├── Node 2: 10.200.1.0/24 (254 Pods)                                     │
│   ├── Node 3: 10.200.2.0/24 (254 Pods)                                     │
│   └── ... (최대 256 노드, 각 노드당 254 Pods)                               │
│                                                                             │
│   Service CIDR: 10.201.0.0/18 (16,382 Services)                            │
│   ├── kubernetes.default: 10.201.0.1                                       │
│   ├── kube-dns: 10.201.0.10                                                │
│   └── 사용자 서비스: 10.201.0.11 ~                                          │
│                                                                             │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │  주의: 세 CIDR은 절대 겹치면 안 됩니다!                               │  │
│   │                                                                       │  │
│   │  물리망: 192.168.108.0/24  ← 노드 간 통신                            │  │
│   │  Pod망:  10.200.0.0/16     ← Pod 간 통신                             │  │
│   │  Svc망:  10.201.0.0/18     ← Service VIP (가상)                      │  │
│   │                                                                       │  │
│   │  기존 네트워크와도 겹치지 않도록 설계 필요                             │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

> **💡 팁 (Tip)**: Pod CIDR을 /16으로 설정하고 노드당 /24를 할당하면, 최대 256개 노드에서 각각 254개의 Pod를 실행할 수 있습니다. 대규모 클러스터에서는 /14나 /12를 고려하세요.

### 3.4. 사설 IP 주소 범위 (RFC 1918)

| 범위 | CIDR | 주소 수 | 용도 |
|------|------|---------|------|
| 10.0.0.0 - 10.255.255.255 | 10.0.0.0/8 | 16,777,216 | 대규모 사설망, Pod CIDR |
| 172.16.0.0 - 172.31.255.255 | 172.16.0.0/12 | 1,048,576 | 중규모 사설망, Docker 기본 |
| 192.168.0.0 - 192.168.255.255 | 192.168.0.0/16 | 65,536 | 소규모 사설망, 가정/사무실 |

> **⚠️ 주의 (Warning)**: Kubernetes 클러스터의 Pod/Service CIDR을 설계할 때, 기존 회사 네트워크와 겹치지 않는지 반드시 확인하세요. VPN으로 연결된 원격 네트워크도 고려해야 합니다.

### 섹션 요약

- IPv4 주소는 **네트워크 부분 + 호스트 부분**으로 구성
- **CIDR** 표기법으로 서브넷을 간결하게 표현 (/24 = 255.255.255.0)
- Kubernetes는 **물리 CIDR, Pod CIDR, Service CIDR** 세 가지 사용
- 세 CIDR은 **절대 겹치면 안 됨**

---

## 4. 라우팅

### 4.1. 라우팅이란?

라우팅은 **패킷이 출발지에서 목적지까지 가는 경로를 결정**하는 과정입니다. 우편물이 주소를 보고 배달되는 것처럼, 패킷도 IP 주소를 보고 다음 홉(hop)을 결정합니다.

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                            라우팅 기본 개념                                   │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   Network A (10.200.0.0/24)              Network B (10.200.1.0/24)          │
│  ┌─────────────────────┐               ┌─────────────────────┐              │
│  │  ┌───┐     ┌───┐    │               │    ┌───┐     ┌───┐  │              │
│  │  │Pod│     │Pod│    │               │    │Pod│     │Pod│  │              │
│  │  │ A │     │ B │    │               │    │ C │     │ D │  │              │
│  │  │.10│     │.20│    │               │    │.10│     │.20│  │              │
│  │  └─┬─┘     └─┬─┘    │               │    └─┬─┘     └─┬─┘  │              │
│  │    └────┬────┘      │               │      └────┬────┘    │              │
│  │         │           │               │           │         │              │
│  │    ┌────┴────┐      │               │      ┌────┴────┐    │              │
│  │    │ cni0    │      │               │      │  cni0   │    │              │
│  │    │ bridge  │      │               │      │ bridge  │    │              │
│  │    └────┬────┘      │               │      └────┬────┘    │              │
│  │         │           │               │           │         │              │
│  │    Node 1           │               │      Node 2         │              │
│  │    192.168.108.101  │               │      192.168.108.102│              │
│  └─────────┼───────────┘               └───────────┼─────────┘              │
│            │                                       │                         │
│            │         ┌─────────────────┐           │                         │
│            └─────────┤  물리 네트워크   ├───────────┘                         │
│                      │  192.168.108.0/24│                                    │
│                      └─────────────────┘                                    │
│                                                                             │
│   Pod A (10.200.0.10) → Pod D (10.200.1.20) 통신 흐름:                      │
│                                                                             │
│   1. Pod A: "10.200.1.20은 내 네트워크(10.200.0.0/24)가 아니네"              │
│      → 기본 게이트웨이로 전송                                                │
│                                                                             │
│   2. Node 1: 라우팅 테이블 조회                                              │
│      "10.200.1.0/24 via 192.168.108.102"                                   │
│      → Node 2로 전송                                                        │
│                                                                             │
│   3. Node 2: "10.200.1.20은 내 로컬 Pod 네트워크"                            │
│      → cni0 브리지를 통해 Pod D로 전달                                       │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

### 4.2. 라우팅 테이블 이해

\`\`\`bash
# Kubernetes 노드의 라우팅 테이블 확인
ip route show

# 출력 예시:
default via 192.168.108.1 dev eth0           # 기본 게이트웨이
10.200.0.0/24 dev cilium_host scope link     # 로컬 Pod CIDR
10.200.1.0/24 via 192.168.108.102 dev eth0   # Node 2의 Pod CIDR
10.200.2.0/24 via 192.168.108.103 dev eth0   # Node 3의 Pod CIDR
10.201.0.0/18 dev cilium_host scope link     # Service CIDR
192.168.108.0/24 dev eth0 proto kernel       # 물리 네트워크
\`\`\`

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                       라우팅 테이블 구조                                     │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   Destination      Gateway           Genmask         Flags  Iface          │
│   ────────────────────────────────────────────────────────────────────     │
│   0.0.0.0          192.168.108.1     0.0.0.0         UG     eth0           │
│   │                │                                  │      │              │
│   │                │                                  │      └─ 출구 인터페이스
│   │                │                                  └─ Up, Gateway        │
│   │                └─ 다음 홉 (next hop)                                    │
│   └─ 목적지 네트워크 (default = 모든 목적지)                                 │
│                                                                             │
│   10.200.0.0       0.0.0.0           255.255.255.0   U      cilium_host    │
│   │                │                                                        │
│   │                └─ 0.0.0.0 = 직접 연결됨 (게이트웨이 필요 없음)           │
│   └─ 로컬 Pod 네트워크                                                      │
│                                                                             │
│   10.200.1.0       192.168.108.102   255.255.255.0   UG     eth0           │
│   │                │                                                        │
│   │                └─ Node 2를 거쳐야 함                                    │
│   └─ Node 2의 Pod 네트워크                                                  │
│                                                                             │
│   라우팅 결정 과정 (Longest Prefix Match):                                  │
│   ──────────────────────────────────────                                   │
│   목적지 10.200.1.50을 찾을 때:                                             │
│   • 10.200.1.0/24 매칭 (24비트 일치) ← 선택됨                               │
│   • 0.0.0.0/0 매칭 (0비트 일치)                                             │
│                                                                             │
│   → 가장 긴 프리픽스가 매칭되는 경로 선택                                    │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

> **📝 예제 (Example)**: Longest Prefix Match 규칙에 따라, 10.200.1.50으로 가는 패킷은 10.200.1.0/24 경로(24비트 매칭)를 선택하고, 8.8.8.8로 가는 패킷은 default(0.0.0.0/0, 0비트 매칭) 경로를 선택합니다.

### 4.3. 라우팅 모드: Native vs Tunnel

Kubernetes CNI는 두 가지 라우팅 모드를 지원합니다:

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                    Native Routing vs Tunnel (VXLAN)                          │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   Native Routing (Direct Routing)                                          │
│   ────────────────────────────────                                         │
│                                                                             │
│   Pod A                                              Pod B                  │
│   10.200.0.10                                        10.200.1.20            │
│       │                                                  ▲                  │
│       │ src: 10.200.0.10                                │                  │
│       │ dst: 10.200.1.20                                │                  │
│       ▼                                                  │                  │
│   [Node 1] ─────────────────────────────────────── [Node 2]                │
│            물리 네트워크에서 Pod IP 그대로 전송                              │
│                                                                             │
│   장점: 오버헤드 없음, 최적 성능                                             │
│   단점: 물리 네트워크가 Pod CIDR 라우팅을 지원해야 함                        │
│         (BGP 피어링 또는 정적 라우팅 설정 필요)                              │
│                                                                             │
│   ─────────────────────────────────────────────────────────────────────    │
│                                                                             │
│   Tunnel Mode (VXLAN)                                                      │
│   ───────────────────                                                      │
│                                                                             │
│   Pod A                                              Pod B                  │
│   10.200.0.10                                        10.200.1.20            │
│       │                                                  ▲                  │
│       │ Inner: src=10.200.0.10, dst=10.200.1.20        │                  │
│       ▼                                                  │                  │
│   [Node 1 VXLAN] ─────────────────────────────── [Node 2 VXLAN]            │
│       │          Outer: src=192.168.108.101              │                  │
│       │                 dst=192.168.108.102              │                  │
│       │          (원본 패킷을 UDP로 캡슐화)               │                  │
│       ▼                                                  │                  │
│   물리 네트워크 (Node IP만 알면 됨)                                          │
│                                                                             │
│   장점: 물리 네트워크 설정 불필요, 어디서든 동작                             │
│   단점: 캡슐화 오버헤드 (MTU 감소, CPU 사용)                                 │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

> **💡 팁 (Tip)**: 같은 L2 네트워크(동일 서브넷)에 있는 노드들은 **Native Routing**이 최적입니다. 다른 서브넷에 있거나, 물리 네트워크 설정을 변경할 수 없는 환경에서는 **VXLAN Tunnel**을 사용합니다.

### 섹션 요약

- 라우팅은 **패킷의 다음 홉을 결정**하는 과정
- 라우팅 테이블에서 **Longest Prefix Match** 규칙으로 경로 선택
- **Native Routing**: 성능 최적, 물리 네트워크 설정 필요
- **VXLAN Tunnel**: 어디서든 동작, 약간의 오버헤드

---

## 5. NAT (Network Address Translation)

### 5.1. NAT의 필요성

NAT는 IP 주소를 변환하는 기술입니다. 주로 두 가지 이유로 사용됩니다:

1. **IP 주소 절약**: 여러 내부 호스트가 하나의 공인 IP 공유
2. **보안**: 내부 네트워크 구조를 외부에 숨김

Kubernetes에서 NAT는 Service 구현의 핵심입니다.

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                            NAT 기본 개념                                     │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   사설 네트워크                    NAT 장치                인터넷            │
│  ┌─────────────────────┐      ┌─────────────┐      ┌─────────────────────┐ │
│  │ PC1: 192.168.1.10   │      │             │      │                     │ │
│  │ PC2: 192.168.1.20   │ ────►│ NAT Router  │ ────►│  웹 서버            │ │
│  │ PC3: 192.168.1.30   │      │ 203.0.113.1 │      │  93.184.216.34      │ │
│  └─────────────────────┘      └─────────────┘      └─────────────────────┘ │
│                                                                             │
│   변환 전:  192.168.1.10:12345 → 93.184.216.34:80                          │
│   변환 후:  203.0.113.1:50001  → 93.184.216.34:80                          │
│                                                                             │
│   NAT 테이블 (연결 추적):                                                    │
│   ┌────────────────────────┬─────────────────────────┐                     │
│   │  내부 (사설)            │  외부 (공인)             │                     │
│   ├────────────────────────┼─────────────────────────┤                     │
│   │  192.168.1.10:12345    │  203.0.113.1:50001     │                     │
│   │  192.168.1.20:12346    │  203.0.113.1:50002     │                     │
│   │  192.168.1.30:12347    │  203.0.113.1:50003     │                     │
│   └────────────────────────┴─────────────────────────┘                     │
│                                                                             │
│   응답 패킷은 NAT 테이블을 역으로 조회하여 원래 호스트로 전달                 │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

### 5.2. SNAT vs DNAT

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                          SNAT vs DNAT                                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   SNAT (Source NAT): 출발지 IP 변경                                         │
│   ═══════════════════════════════════                                       │
│   용도: 내부 → 외부 통신 시 출발지 숨김                                      │
│                                                                             │
│   Pod → 외부 인터넷 통신                                                    │
│                                                                             │
│   ┌─────────┐                    ┌─────────┐                    ┌────────┐ │
│   │  Pod    │   src: 10.200.0.10 │  Node   │   src: 192.168.1.101│ 외부   │ │
│   │10.200.  │  ───────────────►  │  SNAT   │  ───────────────►  │ 서버   │ │
│   │ 0.10    │   dst: 8.8.8.8     │         │   dst: 8.8.8.8     │8.8.8.8 │ │
│   └─────────┘                    └─────────┘                    └────────┘ │
│                                                                             │
│   • Pod IP(10.200.0.10)를 Node IP(192.168.1.101)로 변환                    │
│   • 외부에서는 Pod IP를 알 수 없음                                          │
│   • iptables POSTROUTING 체인에서 처리                                      │
│                                                                             │
│   ─────────────────────────────────────────────────────────────────────    │
│                                                                             │
│   DNAT (Destination NAT): 목적지 IP 변경                                    │
│   ═══════════════════════════════════════                                   │
│   용도: 외부 → 내부 통신 시 목적지 변환 (로드밸런싱)                         │
│                                                                             │
│   외부 Client → NodePort Service → Pod                                     │
│                                                                             │
│   ┌────────┐                    ┌─────────┐                    ┌─────────┐ │
│   │ Client │   dst: NodePort    │  Node   │   dst: 10.200.0.10 │  Pod    │ │
│   │        │  ───────────────►  │  DNAT   │  ───────────────►  │(backend)│ │
│   │        │   192.168.1.101    │         │   :8080            │         │ │
│   │        │   :30080           │         │                    │         │ │
│   └────────┘                    └─────────┘                    └─────────┘ │
│                                                                             │
│   • NodePort(30080)를 Pod IP:Port(10.200.0.10:8080)로 변환                 │
│   • iptables PREROUTING 체인에서 처리                                       │
│   • kube-proxy 또는 Cilium eBPF가 규칙 관리                                 │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

### 5.3. Kubernetes Service와 NAT

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                     Kubernetes Service NAT 흐름                              │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   ClusterIP Service 예시:                                                   │
│   • Service: nginx-svc (ClusterIP: 10.201.50.100:80)                       │
│   • Endpoints: 10.200.0.10:8080, 10.200.1.20:8080, 10.200.2.30:8080        │
│                                                                             │
│   ┌─────────┐                                                              │
│   │ Client  │  1. DNS 조회: nginx-svc.default.svc.cluster.local            │
│   │   Pod   │     → 10.201.50.100                                          │
│   │10.200.  │                                                              │
│   │ 3.50    │  2. 연결 시도: dst = 10.201.50.100:80                        │
│   └────┬────┘                                                              │
│        │                                                                    │
│        ▼                                                                    │
│   ┌─────────────────────────────────────────────────────────────────────┐  │
│   │                     Cilium eBPF / kube-proxy                         │  │
│   │                                                                       │  │
│   │   1. Service IP 매칭: 10.201.50.100:80 → nginx-svc                   │  │
│   │                                                                       │  │
│   │   2. Backend 선택 (로드밸런싱):                                       │  │
│   │      • Round Robin: 순차적으로 선택                                   │  │
│   │      • Maglev: 일관된 해싱 (세션 유지)                                │  │
│   │      → 선택됨: 10.200.1.20:8080                                      │  │
│   │                                                                       │  │
│   │   3. DNAT 수행:                                                       │  │
│   │      dst: 10.201.50.100:80 → 10.200.1.20:8080                        │  │
│   │                                                                       │  │
│   │   4. 연결 추적 (conntrack) 테이블에 기록                              │  │
│   │      (응답 패킷의 역변환을 위해)                                       │  │
│   │                                                                       │  │
│   └─────────────────────────────────────────────────────────────────────┘  │
│        │                                                                    │
│        │ dst: 10.200.1.20:8080                                             │
│        ▼                                                                    │
│   ┌─────────┐                                                              │
│   │ Backend │  3. 요청 처리, 응답 전송                                     │
│   │   Pod   │                                                              │
│   │10.200.  │  4. 응답 패킷: src=10.200.1.20:8080, dst=10.200.3.50        │
│   │ 1.20    │     → conntrack으로 역DNAT                                   │
│   └─────────┘     → Client에게는 src=10.201.50.100:80으로 보임            │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

> **📘 개념 (Concept)**: Kubernetes Service의 ClusterIP는 **가상 IP(VIP)**입니다. 실제로 이 IP에 바인딩된 인터페이스는 없습니다. kube-proxy 또는 Cilium eBPF가 이 IP로 향하는 패킷을 가로채서 실제 Pod IP로 DNAT합니다.

### 5.4. conntrack (Connection Tracking)

NAT가 작동하려면 연결 상태를 추적해야 합니다. Linux의 conntrack 시스템이 이 역할을 합니다.

\`\`\`bash
# conntrack 테이블 확인
conntrack -L

# 출력 예시:
# tcp  6 117 ESTABLISHED src=10.200.3.50 dst=10.201.50.100 sport=54321 dport=80 
#                        src=10.200.1.20 dst=10.200.3.50 sport=8080 dport=54321
#
# 해석:
# 원본: 10.200.3.50:54321 → 10.201.50.100:80 (Service IP)
# 변환: 10.200.1.20:8080 → 10.200.3.50:54321 (응답 경로)

# conntrack 통계
conntrack -S
# cpu=0   entries=1234  searched=567890  found=567800  new=1234  ...
\`\`\`

> **⚠️ 주의 (Warning)**: conntrack 테이블이 가득 차면 새 연결이 거부됩니다. 대규모 클러스터에서는 \`net.netfilter.nf_conntrack_max\` 값을 늘려야 할 수 있습니다. Cilium eBPF 모드는 conntrack을 자체적으로 관리하여 이 문제를 완화합니다.

### 섹션 요약

- **SNAT**: 출발지 IP 변환 (Pod → 외부 통신)
- **DNAT**: 목적지 IP 변환 (Service → Pod 로드밸런싱)
- Kubernetes Service는 **DNAT**로 구현됨
- **conntrack**이 연결 상태를 추적하여 응답 패킷 역변환

---

## 6. Linux 가상 네트워크 장치

### 6.1. veth (Virtual Ethernet)

veth는 **항상 쌍(pair)으로 생성**되는 가상 네트워크 장치입니다. 한쪽 끝에서 들어간 패킷이 다른 쪽 끝에서 나옵니다. 마치 가상의 이더넷 케이블입니다.

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                            veth pair                                        │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   veth pair = 가상 이더넷 케이블                                            │
│   (한쪽 끝에서 들어간 패킷이 다른 쪽에서 나옴)                               │
│                                                                             │
│   ┌───────────────────────────────────────────────────────────────────────┐│
│   │  Container Network Namespace                                          ││
│   │                                                                       ││
│   │   ┌─────────────────────────────────────────────────────────────────┐││
│   │   │  Container (Pod)                                                │││
│   │   │                                                                 │││
│   │   │   eth0 (10.200.0.10/32)  ← 컨테이너 내부에서 보이는 인터페이스   │││
│   │   │     │                                                           │││
│   │   └─────┼───────────────────────────────────────────────────────────┘││
│   │         │ veth pair (한 쪽 끝)                                       ││
│   └─────────┼───────────────────────────────────────────────────────────┘│
│             │                                                             │
│             │ <<< 가상 케이블 >>>                                         │
│             │                                                             │
│   ┌─────────┼───────────────────────────────────────────────────────────┐│
│   │         │ veth pair (다른 쪽 끝)                                     ││
│   │   ┌─────▼─────┐                                                     ││
│   │   │lxcXXXXX   │  ← 호스트에서 보이는 인터페이스 (Cilium 명명 규칙)   ││
│   │   └─────┬─────┘                                                     ││
│   │         │                                                            ││
│   │   ┌─────▼──────────────────────────────────────────────────────────┐││
│   │   │                    Cilium eBPF                                 │││
│   │   │        (또는 Bridge: cni0, docker0)                            │││
│   │   │        패킷 처리, 라우팅 결정                                   │││
│   │   └────────────────────────────────────────────────────────────────┘││
│   │                                                                      ││
│   │  Host Network Namespace                                              ││
│   └──────────────────────────────────────────────────────────────────────┘│
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

**veth 확인:**

\`\`\`bash
# 호스트에서 veth 인터페이스 확인
ip link show type veth

# 특정 veth의 peer 찾기
ip link show lxc12345 | grep -o 'link-netns [^ ]*'
# 또는
ethtool -S lxc12345 | grep peer_ifindex

# Pod 내부에서 인터페이스 확인
kubectl exec -it nginx-pod -- ip addr
# 1: lo: <LOOPBACK,UP,LOWER_UP> ...
# 2: eth0@if123: <BROADCAST,MULTICAST,UP,LOWER_UP> ...
#    link/ether aa:bb:cc:dd:ee:ff
#    inet 10.200.0.10/32 scope global eth0
\`\`\`

### 6.2. Bridge (브리지)

Linux 브리지는 **여러 네트워크 인터페이스를 연결**하는 가상 L2 스위치입니다.

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                           Linux Bridge                                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   Pod 1          Pod 2          Pod 3                                       │
│   ┌────┐         ┌────┐         ┌────┐                                     │
│   │eth0│         │eth0│         │eth0│                                     │
│   └──┬─┘         └──┬─┘         └──┬─┘                                     │
│      │              │              │                                        │
│   ┌──┴──┐        ┌──┴──┐        ┌──┴──┐                                    │
│   │veth1│        │veth2│        │veth3│                                    │
│   └──┬──┘        └──┬──┘        └──┬──┘                                    │
│      │              │              │                                        │
│      └──────────────┼──────────────┘                                        │
│                     │                                                       │
│             ┌───────▼───────┐                                               │
│             │               │                                               │
│             │  cni0 Bridge  │  ← L2 스위치 역할                             │
│             │  10.200.0.1   │  ← Pod들의 기본 게이트웨이                    │
│             │               │                                               │
│             └───────┬───────┘                                               │
│                     │                                                       │
│                     │ 라우팅                                                │
│                     ▼                                                       │
│             ┌───────────────┐                                               │
│             │     eth0      │  ← 물리 인터페이스                            │
│             │192.168.108.101│                                               │
│             └───────────────┘                                               │
│                                                                             │
│   브리지 동작:                                                              │
│   • MAC 주소 학습 (어떤 포트에 어떤 MAC이 있는지)                           │
│   • 같은 브리지 내 Pod 간 통신: 직접 전달 (L2)                              │
│   • 다른 네트워크로 통신: 브리지 IP를 게이트웨이로 라우팅 (L3)              │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

> **📘 개념 (Concept)**: 전통적인 CNI(flannel, calico bridge 모드)는 브리지를 사용합니다. Cilium은 eBPF를 사용하여 브리지 없이도 Pod 네트워킹을 구현할 수 있어 더 효율적입니다.

**브리지 확인:**

\`\`\`bash
# 브리지 목록
ip link show type bridge
# 또는
brctl show

# 브리지에 연결된 인터페이스
bridge link show

# 브리지 MAC 테이블
bridge fdb show br cni0
\`\`\`

### 6.3. TUN/TAP 장치

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                           TUN vs TAP                                         │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   TUN (Layer 3, IP 패킷)                                                   │
│   ──────────────────────                                                    │
│                                                                             │
│   ┌─────────────────┐         ┌─────────────────┐                          │
│   │   Application   │         │   Application   │                          │
│   │   (VPN Client)  │         │   (VPN Server)  │                          │
│   └────────┬────────┘         └────────┬────────┘                          │
│            │                           │                                    │
│            │ read()/write()            │ read()/write()                     │
│            │ IP 패킷                   │ IP 패킷                            │
│            ▼                           ▼                                    │
│   ┌────────────────┐          ┌────────────────┐                           │
│   │    tun0        │◄────────►│     tun0       │                           │
│   │  10.8.0.2      │  암호화   │   10.8.0.1     │                           │
│   └────────────────┘  터널    └────────────────┘                           │
│                                                                             │
│   용도: VPN (OpenVPN, WireGuard), 사용자 공간 라우터                        │
│                                                                             │
│   ─────────────────────────────────────────────────────────────────────    │
│                                                                             │
│   TAP (Layer 2, Ethernet 프레임)                                           │
│   ────────────────────────────────                                          │
│                                                                             │
│   ┌─────────────────┐         ┌─────────────────┐                          │
│   │   Application   │         │   Application   │                          │
│   │   (VM Bridge)   │         │   (VM Bridge)   │                          │
│   └────────┬────────┘         └────────┬────────┘                          │
│            │                           │                                    │
│            │ read()/write()            │ read()/write()                     │
│            │ Ethernet 프레임           │ Ethernet 프레임                    │
│            ▼                           ▼                                    │
│   ┌────────────────┐          ┌────────────────┐                           │
│   │     tap0       │◄────────►│     tap0       │                           │
│   │aa:bb:cc:dd:ee:ff│  L2 터널 │ 11:22:33:44:55:66│                         │
│   └────────────────┘          └────────────────┘                           │
│                                                                             │
│   용도: VM 네트워킹 (QEMU/KVM), L2 VPN, 가상 스위치                         │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

### 섹션 요약

- **veth pair**: 컨테이너와 호스트를 연결하는 가상 케이블
- **Bridge**: 여러 veth를 연결하는 가상 L2 스위치
- **TUN**: L3 패킷을 사용자 공간으로 전달 (VPN)
- **TAP**: L2 프레임을 사용자 공간으로 전달 (VM)

---

## 7. 오버레이 네트워크 (VXLAN)

### 7.1. 오버레이 네트워크란?

오버레이 네트워크는 **기존 물리 네트워크(underlay) 위에 가상의 논리 네트워크를 구축**하는 기술입니다. 마치 우편 시스템에서 편지를 다른 봉투에 넣어 보내는 것과 같습니다.

왜 오버레이가 필요할까요?

1. **물리 네트워크 독립성**: 물리 네트워크 설정을 변경하지 않고 Pod 네트워킹 구현
2. **L2 확장**: 서로 다른 서브넷에 있는 노드 간에도 L2 통신 가능
3. **멀티테넌시**: 테넌트별로 격리된 네트워크 생성

### 7.2. VXLAN (Virtual Extensible LAN)

VXLAN은 가장 널리 사용되는 오버레이 기술입니다. L2 프레임을 UDP 패킷으로 캡슐화합니다.

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                           VXLAN 캡슐화                                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   원본 패킷 (Inner):                                                        │
│   ┌────────────────────────────────────────────────────────┐               │
│   │ Inner Eth │ Inner IP │ Inner TCP/UDP │     Data       │               │
│   │ Src: Pod A│ Src: 10.200.0.10                          │               │
│   │ Dst: Pod B│ Dst: 10.200.1.20                          │               │
│   └────────────────────────────────────────────────────────┘               │
│                              │                                              │
│                              ▼ VXLAN 캡슐화                                 │
│                                                                             │
│   VXLAN 패킷 (Outer):                                                       │
│   ┌──────────────────────────────────────────────────────────────────────┐ │
│   │Outer│Outer IP │Outer UDP│ VXLAN │ Inner │Inner IP│Inner   │  Data   │ │
│   │ Eth │         │Port:4789│Header │  Eth  │        │TCP/UDP │         │ │
│   │     │         │         │VNI:100│       │        │        │         │ │
│   │Src: │Src:     │         │       │Src:   │Src:    │        │         │ │
│   │Node1│192.168. │         │       │Pod A  │10.200. │        │         │ │
│   │MAC  │108.101  │         │       │MAC    │0.10    │        │         │ │
│   │Dst: │Dst:     │         │       │Dst:   │Dst:    │        │         │ │
│   │Node2│192.168. │         │       │Pod B  │10.200. │        │         │ │
│   │MAC  │108.102  │         │       │MAC    │1.20    │        │         │ │
│   └──────────────────────────────────────────────────────────────────────┘ │
│    ◄─── Outer Header (물리망) ───►◄───── Inner Packet (Pod망) ──────►     │
│                                                                             │
│   VXLAN Header (8 bytes):                                                  │
│   • Flags: 8비트                                                            │
│   • VNI (VXLAN Network Identifier): 24비트 → 약 1600만 개의 가상 네트워크  │
│   • Reserved: 24비트 + 8비트                                               │
│                                                                             │
│   특징:                                                                     │
│   • UDP 포트 4789 사용                                                      │
│   • 물리 네트워크는 Node IP만 알면 됨 (Pod IP 몰라도 됨)                    │
│   • 약 50바이트 오버헤드 (MTU 고려 필요: 1500 → 1450)                       │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

### 7.3. VXLAN 통신 흐름

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                        VXLAN Pod 간 통신 흐름                                │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   Node 1 (192.168.108.101)              Node 2 (192.168.108.102)           │
│   VTEP: 192.168.108.101                 VTEP: 192.168.108.102              │
│                                                                             │
│   ┌───────────────────────┐          ┌───────────────────────┐             │
│   │ Pod A                 │          │ Pod B                 │             │
│   │ 10.200.0.10           │          │ 10.200.1.20           │             │
│   │ MAC: aa:bb:cc:11:11:11│          │ MAC: aa:bb:cc:22:22:22│             │
│   │                       │          │      ▲                │             │
│   │ 1. HTTP 요청 생성     │          │      │                │             │
│   │    dst: 10.200.1.20   │          │      │                │             │
│   └───────────┬───────────┘          └──────┼────────────────┘             │
│               │                              │                              │
│               ▼                              │                              │
│   ┌───────────────────────┐          ┌──────┴────────────────┐             │
│   │ 2. VTEP (vxlan.calico)│          │ 6. VTEP              │             │
│   │    또는 cilium_vxlan  │          │    역캡슐화           │             │
│   │                       │          │    (Outer 헤더 제거)  │             │
│   │ • 목적지 Pod B의 위치 │          │                       │             │
│   │   조회 (FDB 테이블)   │          │ • Inner 패킷 추출     │             │
│   │ • VXLAN 캡슐화        │          │ • Pod B로 전달        │             │
│   │   Inner: Pod A → B    │          │                       │             │
│   │   Outer: Node1→Node2  │          └──────▲────────────────┘             │
│   └───────────┬───────────┘                  │                              │
│               │                              │                              │
│               ▼                              │                              │
│   ┌───────────────────────┐          ┌──────┴────────────────┐             │
│   │ 3. eth0               │          │ 5. eth0               │             │
│   │    (물리 인터페이스)    │          │    패킷 수신          │             │
│   └───────────┬───────────┘          └──────▲────────────────┘             │
│               │                              │                              │
│               │    ┌─────────────────┐       │                              │
│               └───►│  물리 네트워크   │───────┘                              │
│                    │192.168.108.0/24 │                                      │
│                    │                 │                                      │
│                    │ 4. UDP 패킷 전송│                                      │
│                    │   src: Node 1   │                                      │
│                    │   dst: Node 2   │                                      │
│                    │   port: 4789    │                                      │
│                    └─────────────────┘                                      │
│                                                                             │
│   VTEP = VXLAN Tunnel EndPoint (터널의 양 끝점)                             │
│   FDB = Forwarding DataBase (MAC → VTEP IP 매핑)                           │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

> **💡 팁 (Tip)**: VXLAN은 MTU 오버헤드(약 50바이트)가 있습니다. 물리 네트워크 MTU가 1500이면, Pod 네트워크 MTU는 1450으로 설정해야 합니다. 점보 프레임(MTU 9000)을 지원하는 환경에서는 이 문제가 완화됩니다.

### 7.4. VXLAN 확인 명령어

\`\`\`bash
# VXLAN 인터페이스 확인
ip -d link show type vxlan

# 출력 예시:
# cilium_vxlan: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 ...
#     vxlan id 1 remote 192.168.108.102 srcport 0 0 dstport 4789 ...

# FDB (Forwarding Database) 테이블 확인
bridge fdb show dev cilium_vxlan
# aa:bb:cc:22:22:22 dst 192.168.108.102 self permanent
# (Pod B의 MAC → Node 2 IP)

# VXLAN 트래픽 캡처
tcpdump -i eth0 udp port 4789 -nn

# VXLAN 내부 패킷까지 디코딩
tcpdump -i eth0 udp port 4789 -nn -e -v
\`\`\`

### 섹션 요약

- **오버레이 네트워크**: 물리 네트워크 위에 가상 네트워크 구축
- **VXLAN**: L2 프레임을 UDP로 캡슐화 (포트 4789)
- **VTEP**: VXLAN 터널의 끝점, 캡슐화/역캡슐화 수행
- **오버헤드**: 약 50바이트, MTU 조정 필요

---

## 8. iptables와 netfilter

### 8.1. netfilter 아키텍처

netfilter는 Linux 커널의 패킷 필터링 프레임워크입니다. iptables는 netfilter를 제어하는 사용자 공간 도구입니다.

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                        netfilter 패킷 흐름                                   │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│                          ┌─────────────────┐                                │
│                          │   Network       │                                │
│                          │   Interface     │                                │
│                          └────────┬────────┘                                │
│                                   │ 패킷 수신                               │
│                                   ▼                                         │
│                       ┌───────────────────────┐                             │
│                       │      PREROUTING       │ ← DNAT (Service → Pod)     │
│                       │  (raw, mangle, nat)   │                             │
│                       └───────────┬───────────┘                             │
│                                   │                                         │
│                                   ▼                                         │
│                       ┌───────────────────────┐                             │
│                       │   Routing Decision    │                             │
│                       │   (목적지 확인)        │                             │
│                       └───────────┬───────────┘                             │
│                                   │                                         │
│              ┌────────────────────┼────────────────────┐                    │
│              │                    │                    │                    │
│              ▼                    │                    ▼                    │
│   ┌─────────────────┐            │         ┌─────────────────┐             │
│   │     INPUT       │  로컬 목적지│         │    FORWARD      │ 다른 호스트  │
│   │ (mangle,filter) │            │         │ (mangle,filter) │ 목적지       │
│   └────────┬────────┘            │         └────────┬────────┘             │
│            │                      │                  │                      │
│            ▼                      │                  │                      │
│   ┌─────────────────┐            │                  │                      │
│   │  Local Process  │            │                  │                      │
│   │  (Application)  │            │                  │                      │
│   └────────┬────────┘            │                  │                      │
│            │ 응답/송신            │                  │                      │
│            ▼                      │                  │                      │
│   ┌─────────────────┐            │                  │                      │
│   │     OUTPUT      │            │                  │                      │
│   │(raw,mangle,nat, │            │                  │                      │
│   │    filter)      │            │                  │                      │
│   └────────┬────────┘            │                  │                      │
│            │                      │                  │                      │
│            └──────────────────────┼──────────────────┘                      │
│                                   │                                         │
│                                   ▼                                         │
│                       ┌───────────────────────┐                             │
│                       │     POSTROUTING       │ ← SNAT (Pod → 외부)        │
│                       │    (mangle, nat)      │                             │
│                       └───────────┬───────────┘                             │
│                                   │                                         │
│                                   ▼                                         │
│                          ┌─────────────────┐                                │
│                          │   Network       │                                │
│                          │   Interface     │                                │
│                          └─────────────────┘                                │
│                                                                             │
│   체인별 역할:                                                               │
│   • PREROUTING: 패킷 도착 직후 (DNAT)                                       │
│   • INPUT: 로컬 프로세스로 가는 패킷 (방화벽)                                │
│   • FORWARD: 다른 호스트로 전달되는 패킷 (라우터 역할)                       │
│   • OUTPUT: 로컬 프로세스가 보내는 패킷                                      │
│   • POSTROUTING: 패킷 전송 직전 (SNAT, Masquerade)                          │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

### 8.2. iptables 기본 사용법

\`\`\`bash
# 현재 규칙 확인 (nat 테이블)
iptables -t nat -L -n -v

# 현재 규칙 확인 (filter 테이블, 기본)
iptables -L -n -v

# Kubernetes Service 관련 규칙 (kube-proxy 모드)
iptables -t nat -L KUBE-SERVICES -n

# 특정 체인의 규칙 확인
iptables -t nat -L PREROUTING -n -v --line-numbers

# 규칙 추가 예시
iptables -A INPUT -p tcp --dport 22 -j ACCEPT   # SSH 허용
iptables -A INPUT -p tcp --dport 80 -j DROP     # HTTP 차단

# 규칙 삭제
iptables -D INPUT -p tcp --dport 80 -j DROP

# NAT 규칙 예시 (SNAT)
iptables -t nat -A POSTROUTING -s 10.200.0.0/16 -o eth0 -j MASQUERADE

# NAT 규칙 예시 (DNAT)
iptables -t nat -A PREROUTING -p tcp --dport 30080 -j DNAT --to-destination 10.200.0.10:8080
\`\`\`

### 8.3. Kubernetes와 iptables

\`\`\`
┌─────────────────────────────────────────────────────────────────────────────┐
│                    kube-proxy iptables 모드                                  │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   Service: nginx-svc (ClusterIP: 10.201.50.100:80)                         │
│   Endpoints: 10.200.0.10:8080, 10.200.1.20:8080                            │
│                                                                             │
│   iptables 규칙 체인:                                                       │
│                                                                             │
│   PREROUTING                                                                │
│       │                                                                     │
│       └──► KUBE-SERVICES                                                   │
│                │                                                            │
│                ├──► KUBE-SVC-XXXX (nginx-svc)                              │
│                │        │                                                   │
│                │        ├── 50% ──► KUBE-SEP-AAAA (10.200.0.10:8080)       │
│                │        │               └── DNAT to 10.200.0.10:8080       │
│                │        │                                                   │
│                │        └── 50% ──► KUBE-SEP-BBBB (10.200.1.20:8080)       │
│                │                        └── DNAT to 10.200.1.20:8080       │
│                │                                                            │
│                ├──► KUBE-SVC-YYYY (다른 서비스)                             │
│                │        ...                                                 │
│                │                                                            │
│                └──► KUBE-NODEPORTS (NodePort 처리)                         │
│                                                                             │
│   문제점:                                                                   │
│   • 서비스/엔드포인트 증가 → iptables 규칙 증가 → 성능 저하               │
│   • O(n) 순차 탐색 (규칙 수에 비례하여 느려짐)                              │
│   • 규칙 변경 시 전체 테이블 재작성                                         │
│                                                                             │
│   Cilium eBPF 대안:                                                        │
│   • O(1) 해시 테이블 룩업                                                   │
│   • iptables 규칙 불필요 (kube-proxy 대체)                                  │
│   • conntrack 최적화                                                        │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
\`\`\`

> **⚠️ 주의 (Warning)**: 대규모 클러스터(1000+ Services)에서 iptables 모드는 성능 문제가 발생할 수 있습니다. Cilium eBPF 또는 kube-proxy IPVS 모드를 고려하세요.

### 8.4. 디버깅 도구

\`\`\`bash
# 패킷이 어떤 규칙에 매칭되는지 추적
iptables -t nat -L -n -v | grep -i "pkts"
# pkts 카운터로 어떤 규칙이 사용되는지 확인

# 연결 추적 테이블
conntrack -L
conntrack -L -p tcp --dport 80

# iptables 규칙 저장/복원
iptables-save > /tmp/iptables-backup
iptables-restore < /tmp/iptables-backup

# TRACE 활성화 (디버깅용)
iptables -t raw -A PREROUTING -p tcp --dport 80 -j TRACE
# dmesg 또는 /var/log/kern.log에서 추적 로그 확인

# nftables 사용 시 (최신 시스템)
nft list ruleset
\`\`\`

### 섹션 요약

- **netfilter**: Linux 커널의 패킷 필터링 프레임워크
- **iptables**: netfilter를 제어하는 사용자 도구
- **5개 체인**: PREROUTING, INPUT, FORWARD, OUTPUT, POSTROUTING
- kube-proxy는 iptables 규칙으로 Service 구현 (대안: Cilium eBPF)

---

## 이 장의 요약

이 장에서는 Kubernetes 네트워킹을 이해하기 위한 핵심 네트워크 기초를 학습했습니다:

| 개념 | 설명 | Kubernetes에서의 역할 |
|------|------|---------------------|
| **OSI 7계층** | 네트워크 통신을 7개 계층으로 추상화한 모델 | 각 계층별 문제 분리 및 디버깅 기준점 |
| **TCP/IP 스택** | 실제 인터넷에서 사용되는 4계층 프로토콜 스택 | Pod 간 통신, Service 연결의 기반 |
| **IP 주소 / 서브넷** | 네트워크 주소 체계와 네트워크 분할 | Pod CIDR, Service CIDR, 노드 네트워크 설계 |
| **라우팅** | 패킷의 목적지 경로 결정 | CNI가 Pod 서브넷 간 라우팅 테이블 관리 |
| **NAT (SNAT/DNAT)** | 주소 변환을 통한 네트워크 연결 | NodePort, LoadBalancer, 외부 통신 처리 |
| **veth pair** | 가상 이더넷 페어로 네임스페이스 연결 | Pod와 호스트 네트워크 연결의 핵심 |
| **Linux Bridge** | 소프트웨어 스위치로 L2 연결 | 동일 노드 내 Pod 간 통신 |
| **TUN/TAP** | 커널-유저스페이스 간 패킷 전달 | VPN, 오버레이 네트워크 구현 |
| **VXLAN** | UDP 기반 L2 오버레이 네트워크 | 멀티 노드 Pod 네트워크 (Flannel, Cilium) |
| **iptables/netfilter** | Linux 커널 패킷 필터링 프레임워크 | kube-proxy의 Service 구현 (iptables 모드) |

### 핵심 통찰

1. **모든 것은 결국 IP 패킷**: Kubernetes의 복잡한 네트워킹도 기본 원리는 IP 라우팅과 NAT입니다.

2. **가상 네트워크 장치의 조합**: veth + bridge + VXLAN의 조합으로 Pod 네트워크가 구현됩니다.

3. **오버레이 vs 언더레이**: VXLAN 오버레이는 유연하지만 오버헤드가 있고, Direct Routing은 빠르지만 인프라 지원이 필요합니다.

4. **iptables의 한계**: 대규모 클러스터에서 iptables 성능 문제 → eBPF 기반 솔루션(Cilium)의 등장 배경입니다.

> **📘 개념 (Concept)**: 네트워크 기초를 이해하면 Kubernetes 네트워크 문제의 90%는 "어느 계층에서 문제인가?"를 파악하는 것으로 시작합니다. OSI 모델을 따라 아래에서 위로 디버깅하세요.

---

## 실습 과제

### 과제 1: 네트워크 네임스페이스와 veth pair

**목표**: 네트워크 네임스페이스와 veth pair를 직접 생성하여 Pod 네트워킹의 기초를 이해합니다.

```bash
# 1. 두 개의 네트워크 네임스페이스 생성
sudo ip netns add pod-a
sudo ip netns add pod-b

# 2. veth pair 생성 및 각 네임스페이스에 할당
sudo ip link add veth-a type veth peer name veth-b
sudo ip link set veth-a netns pod-a
sudo ip link set veth-b netns pod-b

# 3. IP 주소 할당 및 인터페이스 활성화
sudo ip netns exec pod-a ip addr add 10.200.1.10/24 dev veth-a
sudo ip netns exec pod-a ip link set veth-a up
sudo ip netns exec pod-a ip link set lo up

sudo ip netns exec pod-b ip addr add 10.200.1.20/24 dev veth-b
sudo ip netns exec pod-b ip link set veth-b up
sudo ip netns exec pod-b ip link set lo up

# 4. 통신 테스트
sudo ip netns exec pod-a ping -c 3 10.200.1.20

# 5. 정리
sudo ip netns delete pod-a
sudo ip netns delete pod-b
```

**도전 과제**: 
- `tcpdump`로 veth 인터페이스의 패킷을 캡처해보세요
- ARP 테이블(`ip neigh`)이 어떻게 채워지는지 확인하세요

---

### 과제 2: Linux Bridge를 이용한 멀티 Pod 네트워크

**목표**: Bridge를 사용하여 여러 네임스페이스가 통신하는 환경을 구축합니다.

```bash
# 1. 브리지 생성
sudo ip link add br0 type bridge
sudo ip link set br0 up
sudo ip addr add 10.200.1.1/24 dev br0

# 2. 세 개의 "Pod" 네임스페이스 생성
for i in 1 2 3; do
    sudo ip netns add pod-$i
    sudo ip link add veth-pod$i type veth peer name veth-br$i
    sudo ip link set veth-pod$i netns pod-$i
    sudo ip link set veth-br$i master br0
    sudo ip link set veth-br$i up
    sudo ip netns exec pod-$i ip addr add 10.200.1.1$i/24 dev veth-pod$i
    sudo ip netns exec pod-$i ip link set veth-pod$i up
    sudo ip netns exec pod-$i ip link set lo up
    sudo ip netns exec pod-$i ip route add default via 10.200.1.1
done

# 3. Pod 간 통신 테스트
sudo ip netns exec pod-1 ping -c 2 10.200.1.12  # pod-1 → pod-2
sudo ip netns exec pod-2 ping -c 2 10.200.1.13  # pod-2 → pod-3
sudo ip netns exec pod-3 ping -c 2 10.200.1.11  # pod-3 → pod-1

# 4. 브리지 상태 확인
bridge link show br0

# 5. 정리
for i in 1 2 3; do sudo ip netns delete pod-$i; done
sudo ip link delete br0
```

**도전 과제**:
- `bridge fdb show br0`로 MAC 주소 테이블을 확인하세요
- 호스트에서 Pod로 ping이 가능한지 확인하세요

---

### 과제 3: NAT 규칙으로 외부 통신 구현

**목표**: SNAT/MASQUERADE를 설정하여 네트워크 네임스페이스에서 외부로 통신할 수 있게 합니다.

```bash
# 1. 네임스페이스 및 네트워크 설정 (과제 2의 환경 재사용 또는 새로 생성)
sudo ip netns add pod-nat
sudo ip link add veth-pod type veth peer name veth-host
sudo ip link set veth-pod netns pod-nat
sudo ip link set veth-host up
sudo ip addr add 10.200.100.1/24 dev veth-host
sudo ip netns exec pod-nat ip addr add 10.200.100.10/24 dev veth-pod
sudo ip netns exec pod-nat ip link set veth-pod up
sudo ip netns exec pod-nat ip link set lo up
sudo ip netns exec pod-nat ip route add default via 10.200.100.1

# 2. IP 포워딩 활성화
echo 1 | sudo tee /proc/sys/net/ipv4/ip_forward

# 3. MASQUERADE 규칙 추가 (eth0을 실제 외부 인터페이스로 변경)
# 먼저 현재 인터페이스 확인: ip route | grep default
sudo iptables -t nat -A POSTROUTING -s 10.200.100.0/24 -o eth0 -j MASQUERADE

# 4. 외부 통신 테스트
sudo ip netns exec pod-nat ping -c 2 8.8.8.8
sudo ip netns exec pod-nat curl -s --connect-timeout 5 http://ifconfig.me

# 5. NAT 테이블 확인
sudo iptables -t nat -L POSTROUTING -n -v

# 6. 정리
sudo ip netns delete pod-nat
sudo ip link delete veth-host 2>/dev/null
sudo iptables -t nat -D POSTROUTING -s 10.200.100.0/24 -o eth0 -j MASQUERADE
```

**도전 과제**:
- DNAT 규칙을 추가하여 호스트의 특정 포트를 Pod로 포워딩해보세요
- `conntrack -L`로 연결 추적 테이블을 확인하세요

---

### 과제 4: VXLAN 오버레이 네트워크 구성 (멀티 노드 시뮬레이션)

**목표**: 단일 호스트에서 VXLAN을 사용하여 멀티 노드 오버레이 네트워크를 시뮬레이션합니다.

```bash
# 시뮬레이션: 두 개의 "노드"를 네임스페이스로 표현

# 1. "노드" 네임스페이스 생성 (언더레이 네트워크)
sudo ip netns add node-1
sudo ip netns add node-2

# 2. 노드 간 연결 (언더레이)
sudo ip link add veth-n1 type veth peer name veth-n2
sudo ip link set veth-n1 netns node-1
sudo ip link set veth-n2 netns node-2

sudo ip netns exec node-1 ip addr add 192.168.1.1/24 dev veth-n1
sudo ip netns exec node-1 ip link set veth-n1 up
sudo ip netns exec node-1 ip link set lo up

sudo ip netns exec node-2 ip addr add 192.168.1.2/24 dev veth-n2
sudo ip netns exec node-2 ip link set veth-n2 up
sudo ip netns exec node-2 ip link set lo up

# 3. 각 노드에 VXLAN 인터페이스 생성 (오버레이)
sudo ip netns exec node-1 ip link add vxlan100 type vxlan id 100 \
    local 192.168.1.1 remote 192.168.1.2 dstport 4789 dev veth-n1
sudo ip netns exec node-1 ip addr add 10.200.0.1/24 dev vxlan100
sudo ip netns exec node-1 ip link set vxlan100 up

sudo ip netns exec node-2 ip link add vxlan100 type vxlan id 100 \
    local 192.168.1.2 remote 192.168.1.1 dstport 4789 dev veth-n2
sudo ip netns exec node-2 ip addr add 10.200.0.2/24 dev vxlan100
sudo ip netns exec node-2 ip link set vxlan100 up

# 4. 오버레이 네트워크 통신 테스트
sudo ip netns exec node-1 ping -c 3 10.200.0.2

# 5. 언더레이에서 VXLAN 패킷 캡처 (별도 터미널)
# sudo ip netns exec node-1 tcpdump -i veth-n1 -nn udp port 4789

# 6. 정리
sudo ip netns delete node-1
sudo ip netns delete node-2
```

**도전 과제**:
- 각 "노드"에 추가 네임스페이스를 만들어 "Pod"를 시뮬레이션하세요
- VXLAN 패킷을 tcpdump로 캡처하고 구조를 분석하세요

---

### 과제 5: Kubernetes 클러스터에서 네트워크 디버깅

**목표**: 실제 Kubernetes 클러스터에서 네트워크 스택을 탐색하고 디버깅 명령어를 연습합니다.

```bash
# 1. Pod 네트워크 네임스페이스 확인
kubectl get pods -o wide
# Pod가 실행 중인 노드에서:
crictl ps | grep <pod-name>
crictl inspect <container-id> | jq '.info.pid'
# 해당 PID의 네트워크 네임스페이스 진입
sudo nsenter -t <pid> -n ip addr

# 2. CNI 구성 확인
cat /etc/cni/net.d/*.conf
ls -la /opt/cni/bin/

# 3. Pod에서 DNS 및 Service 연결 테스트
kubectl exec -it <pod-name> -- nslookup kubernetes.default
kubectl exec -it <pod-name> -- wget -O- http://kubernetes.default.svc:443 --timeout=2

# 4. Service의 iptables 규칙 확인 (kube-proxy iptables 모드)
sudo iptables -t nat -L KUBE-SERVICES -n | head -20
sudo iptables -t nat -L -n | grep <service-clusterip>

# 5. 노드 간 Pod 통신 경로 추적
kubectl exec -it <pod-on-node1> -- traceroute <pod-ip-on-node2>

# 6. CNI별 상태 확인
# Cilium인 경우:
kubectl exec -it -n kube-system cilium-xxxxx -- cilium status
kubectl exec -it -n kube-system cilium-xxxxx -- cilium bpf lb list

# Flannel인 경우:
ip route | grep flannel
bridge fdb show dev flannel.1
```

**도전 과제**:
- 두 Pod 간 통신 경로에서 모든 네트워크 장치(veth, bridge, VXLAN 등)를 식별하세요
- `tcpdump`로 Service 요청이 어떻게 Pod로 전달되는지 추적하세요

---

## 학습 점검

### 질문 1: OSI 모델에서 라우터는 어느 계층에서 동작하나요?

<details>
<summary>정답 보기</summary>

**Layer 3 (네트워크 계층)**

라우터는 IP 주소를 기반으로 패킷의 경로를 결정하므로 OSI 모델의 3계층(네트워크 계층)에서 동작합니다. 

- **Layer 2 (데이터 링크 계층)**: 스위치 - MAC 주소 기반 프레임 전달
- **Layer 3 (네트워크 계층)**: 라우터 - IP 주소 기반 패킷 라우팅
- **Layer 4 (전송 계층)**: 방화벽(일부) - TCP/UDP 포트 기반 필터링

Kubernetes에서 CNI는 기본적으로 Layer 3 라우팅을 수행하며, Service는 Layer 4 로드밸런싱을 제공합니다.

</details>

---

### 질문 2: CIDR 표기법 10.200.0.0/16에서 사용 가능한 IP 주소 개수는 몇 개인가요?

<details>
<summary>정답 보기</summary>

**65,534개** (실제 할당 가능한 호스트 주소)

계산:
- /16 = 16비트가 네트워크 부분, 나머지 16비트가 호스트 부분
- 호스트 부분: 2^16 = 65,536개
- 네트워크 주소(10.200.0.0)와 브로드캐스트 주소(10.200.255.255)를 제외하면: 65,536 - 2 = **65,534개**

Kubernetes 관점:
- 이 서브넷은 Pod CIDR로 사용될 경우 약 65,000개의 Pod에 IP를 할당할 수 있습니다
- 실제로는 각 노드에 /24 서브넷을 할당하므로: 256개의 노드 × 254개의 Pod/노드 = 약 65,000개

</details>

---

### 질문 3: veth pair의 한쪽 끝에서 패킷을 전송하면 어디로 전달되나요?

<details>
<summary>정답 보기</summary>

**veth pair의 반대쪽 끝으로 즉시 전달됩니다.**

veth pair는 가상 이더넷 케이블처럼 동작합니다:
- 한쪽(veth-a)에서 들어온 패킷은 다른 쪽(veth-b)으로 나갑니다
- 두 인터페이스는 서로 다른 네트워크 네임스페이스에 있을 수 있습니다
- 이것이 Pod(자체 네임스페이스)와 호스트 네트워크를 연결하는 핵심 메커니즘입니다

```
┌─────────────────┐                    ┌─────────────────┐
│   Pod 네임스페이스  │                    │   호스트 네임스페이스  │
│                 │                    │                 │
│    eth0(veth-a) │◄═══════════════════►│ vethXXX(veth-b)│
│                 │    veth pair       │                 │
└─────────────────┘                    └─────────────────┘
```

</details>

---

### 질문 4: SNAT와 DNAT의 차이점을 설명하세요.

<details>
<summary>정답 보기</summary>

**SNAT (Source NAT)**: 패킷의 **출발지 주소**를 변경
- 용도: 내부 네트워크에서 외부로 나갈 때 사설 IP를 공인 IP로 변환
- Kubernetes: Pod가 외부 인터넷으로 통신할 때 노드 IP로 SNAT
- 처리 위치: POSTROUTING 체인 (패킷이 나가기 직전)

**DNAT (Destination NAT)**: 패킷의 **목적지 주소**를 변경
- 용도: 외부에서 들어오는 트래픽을 내부의 특정 서버로 전달
- Kubernetes: NodePort/LoadBalancer로 들어온 트래픽을 Pod IP로 DNAT
- 처리 위치: PREROUTING 체인 (패킷이 라우팅되기 전)

```
외부 → [DNAT: 노드IP:30080 → Pod IP:8080] → Pod
Pod → [SNAT: Pod IP → 노드IP] → 외부
```

</details>

---

### 질문 5: Linux Bridge와 veth pair를 함께 사용하는 이유는 무엇인가요?

<details>
<summary>정답 보기</summary>

**여러 네트워크 네임스페이스(Pod)를 Layer 2에서 연결하기 위해서입니다.**

- **veth pair만 사용**: 1:1 연결만 가능 (Pod A ↔ 호스트)
- **Bridge 추가**: 여러 veth를 하나의 스위치에 연결하여 다대다 통신 가능

```
┌─────────┐  ┌─────────┐  ┌─────────┐
│  Pod A  │  │  Pod B  │  │  Pod C  │
│  eth0   │  │  eth0   │  │  eth0   │
└────┬────┘  └────┬────┘  └────┬────┘
     │            │            │
   veth-a       veth-b       veth-c
     │            │            │
     └────────────┼────────────┘
                  │
            ┌─────┴─────┐
            │   br0     │  ← Linux Bridge
            │ (스위치)   │
            └───────────┘
```

Bridge는 MAC 주소 테이블을 학습하여 프레임을 적절한 포트로 전달합니다. 이것이 동일 노드 내 Pod 간 통신의 기본 구조입니다.

</details>

---

### 질문 6: VXLAN에서 VNI(VXLAN Network Identifier)의 역할은 무엇인가요?

<details>
<summary>정답 보기</summary>

**VNI는 오버레이 네트워크를 논리적으로 분리하는 식별자입니다** (VLAN ID와 유사한 역할).

- **범위**: 24비트 → 약 1,600만 개의 고유 네트워크 식별 가능
- **용도**: 동일한 물리 인프라에서 여러 테넌트/네트워크를 격리
- **동작**: 같은 VNI를 가진 VXLAN 엔드포인트들만 서로 통신

```
┌─────────────────────────────────────────────┐
│            VXLAN 헤더 (8 bytes)              │
├─────────────────────────────────────────────┤
│ Flags (8b) │ Reserved (24b) │ VNI (24b) │ Reserved (8b) │
│            │                │  100      │               │
└─────────────────────────────────────────────┘
```

Kubernetes CNI에서:
- Flannel: 기본 VNI = 1
- Cilium: VXLAN 또는 Geneve 사용 (VNI로 네트워크 식별)

</details>

---

### 질문 7: iptables에서 PREROUTING과 POSTROUTING 체인의 처리 순서 차이는?

<details>
<summary>정답 보기</summary>

**PREROUTING**: 패킷이 라우팅 결정을 **받기 전**에 처리
**POSTROUTING**: 패킷이 라우팅 결정을 받고 **나간 후**에 처리

```
패킷 도착
    │
    ▼
┌─────────────┐
│ PREROUTING  │ ← DNAT 처리 (목적지 주소 변경)
└──────┬──────┘
       │
       ▼
┌─────────────┐
│  라우팅 결정  │ ← 어디로 보낼지 결정
└──────┬──────┘
       │
    ┌──┴──┐
    │     │
    ▼     ▼
 INPUT  FORWARD
    │     │
    ▼     ▼
┌─────────────┐
│ POSTROUTING │ ← SNAT 처리 (출발지 주소 변경)
└──────┬──────┘
       │
       ▼
   패킷 전송
```

- PREROUTING에서 DNAT을 해야 라우팅 결정이 변경된 목적지를 기준으로 이루어집니다
- POSTROUTING에서 SNAT을 해야 응답 패킷이 올바른 출발지로 돌아갑니다

</details>

---

### 질문 8: Kubernetes에서 kube-proxy iptables 모드의 주요 단점은 무엇인가요?

<details>
<summary>정답 보기</summary>

**대규모 클러스터에서 성능 저하가 발생합니다:**

1. **O(n) 규칙 탐색**: Service/Endpoint가 증가하면 iptables 규칙도 선형 증가, 매 패킷마다 순차 탐색

2. **전체 테이블 재작성**: Endpoint 하나가 변경되어도 전체 iptables 규칙 갱신 필요

3. **규칙 수 폭발**: 1000개 Service × 10개 Endpoint = 수만 개의 iptables 규칙

4. **conntrack 테이블 부하**: 연결 추적 테이블 관리 오버헤드

**대안:**
- **IPVS 모드**: 해시 테이블 기반 O(1) 룩업, 대규모 클러스터에 적합
- **Cilium eBPF**: iptables 완전 대체, 커널 수준 최적화, kube-proxy 불필요

```
# 규칙 수 비교 (1000 Services, 10 Endpoints each)
iptables 모드: ~20,000+ 규칙
IPVS 모드: ~1,000 가상 서버 (해시 테이블)
Cilium eBPF: eBPF 맵 (O(1) 해시 룩업)
```

</details>

---

### 질문 9: Pod A(10.200.0.10)에서 Pod B(10.200.1.20, 다른 노드)로 패킷이 전달되는 과정을 간략히 설명하세요 (VXLAN 기반 CNI 가정).

<details>
<summary>정답 보기</summary>

**VXLAN 오버레이를 통한 노드 간 Pod 통신 과정:**

```
1. Pod A (10.200.0.10) → eth0 (veth pair)
        │
        ▼
2. 호스트 네트워크 (veth) → 라우팅 테이블 확인
   "10.200.1.0/24 → VXLAN 장치로"
        │
        ▼
3. VXLAN 인터페이스 (캡슐화)
   ┌────────────────────────────────────────┐
   │ 외부 IP헤더  │ UDP│ VXLAN │ 원본 프레임  │
   │ Src: Node1  │:4789│ VNI  │ Dst:10.200.1.20│
   │ Dst: Node2  │    │ 100  │               │
   └────────────────────────────────────────┘
        │
        ▼
4. 물리 네트워크 (언더레이) 전송
   Node1 (192.168.1.1) → Node2 (192.168.1.2)
        │
        ▼
5. Node2 VXLAN 인터페이스 (디캡슐화)
   외부 헤더 제거 → 원본 프레임 추출
        │
        ▼
6. Node2 라우팅 → Pod B의 veth pair
        │
        ▼
7. Pod B (10.200.1.20) eth0 수신
```

핵심: **오버레이 네트워크는 Pod IP를 물리 네트워크(언더레이)와 독립적으로 유지**합니다.

</details>

---

### 질문 10: 네트워크 문제 디버깅 시 "아래에서 위로" 접근법이 중요한 이유는?

<details>
<summary>정답 보기</summary>

**하위 계층 문제가 상위 계층에 영향을 주기 때문입니다.**

상위 계층(Application)에서 문제가 보여도 실제 원인은 하위 계층에 있을 수 있습니다:

| 계층 | 확인 사항 | 도구 |
|------|----------|------|
| L1/L2 | 물리 연결, 인터페이스 상태 | `ip link`, `ethtool` |
| L3 | IP 주소, 라우팅, 연결성 | `ip addr`, `ip route`, `ping` |
| L4 | 포트 열림, 방화벽 규칙 | `ss`, `netstat`, `iptables` |
| L7 | 애플리케이션 응답 | `curl`, 애플리케이션 로그 |

**디버깅 순서:**

```
1. ip link show        → 인터페이스가 UP인가?
2. ip addr show        → IP가 할당되어 있나?
3. ip route            → 경로가 있나?
4. ping <gateway>      → 게이트웨이까지 도달 가능?
5. ping <destination>  → 목적지까지 도달 가능?
6. curl http://...     → 애플리케이션 응답?
```

"위에서 아래로" 접근하면 시간 낭비:
- "curl이 안 돼요" → 사실 IP 주소가 잘못됨 (L3 문제)
- "Service에 연결 안 돼요" → 사실 veth pair가 다운됨 (L2 문제)

</details>

---

## 다음 단계

이 장에서 학습한 네트워킹 기초를 바탕으로, 다음 장에서는 **Kubernetes 아키텍처**를 심층적으로 살펴봅니다:

- **Control Plane 컴포넌트**: API Server, etcd, Scheduler, Controller Manager
- **Worker Node 컴포넌트**: kubelet, kube-proxy, Container Runtime
- **Pod 생명주기**: Pod이 어떻게 스케줄링되고 실행되는가
- **Service 네트워킹**: ClusterIP, NodePort, LoadBalancer의 내부 동작
- **Storage 추상화**: PV, PVC, StorageClass
- **Controller 패턴**: Reconciliation Loop의 이해

네트워킹 기초가 탄탄하면 Kubernetes의 CNI(Container Network Interface)가 어떻게 Pod 네트워크를 구현하는지, Service가 내부적으로 어떻게 동작하는지 깊이 이해할 수 있습니다.

---

## 참고 자료

### 공식 문서

- [Linux Network Namespaces - man7.org](https://man7.org/linux/man-pages/man7/network_namespaces.7.html)
- [iproute2 documentation](https://wiki.linuxfoundation.org/networking/iproute2)
- [iptables Tutorial](https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html)
- [VXLAN - IETF RFC 7348](https://datatracker.ietf.org/doc/html/rfc7348)

### 심화 학습

- [Linux 네트워크 내부 구조 (O'Reilly)](https://www.oreilly.com/library/view/understanding-linux-network/0596002556/)
- [Kubernetes Networking Deep Dive - Tigera](https://www.tigera.io/learn/guides/kubernetes-networking/)
- [CNI Specification](https://github.com/containernetworking/cni/blob/master/SPEC.md)
- [Cilium Documentation - Networking](https://docs.cilium.io/en/stable/network/)

### 실습 환경

- [Katacoda - Linux Networking](https://www.katacoda.com/courses/linux)
- [Network Policy Recipes](https://github.com/ahmetb/kubernetes-network-policy-recipes)
- [Kubernetes the Hard Way - Kelsey Hightower](https://github.com/kelseyhightower/kubernetes-the-hard-way)

### 디버깅 도구

- `tcpdump` - 패킷 캡처 및 분석
- `wireshark` - GUI 기반 패킷 분석
- `ss` / `netstat` - 소켓 통계
- `ip` - 네트워크 구성 도구
- `bridge` - Linux Bridge 관리
- `conntrack` - 연결 추적 테이블 조회

---

> **💡 팁 (Tip)**: 네트워크 디버깅 실력은 문제를 직접 만들어보고 해결하면서 늘어납니다. 실습 과제를 반복하면서 각 도구의 출력을 해석하는 연습을 하세요. 실제 Kubernetes 클러스터에서 `tcpdump`와 `ip` 명령어를 자유롭게 사용할 수 있다면, 대부분의 네트워크 문제를 스스로 해결할 수 있습니다.
